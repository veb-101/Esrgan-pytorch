{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bgUXGjui40a",
    "outputId": "5a888252-b677-4190-d961-6339e724f221"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 22 08:28:04 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   65C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jLYuG7EqbnTR",
    "outputId": "32e2112b-739f-4d0d-dca5-94007673222d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMpN3TjpHOHP",
    "outputId": "6e02a858-e779-4750-d29e-67c430d14f38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1T8IZ4huhbVGW2eVUJOcUFuk7m5HlkEpg into ./images/lr.zip... \n",
      "373.5 MiB Done.\n",
      "Downloading 1HQUi1ZZpPHXMO1swNKywcwwVNyqwYJNu into ./images/hr.zip... \n",
      "5.3 GiB Done.\n",
      "Unzipping...Done.\n"
     ]
    }
   ],
   "source": [
    "# @title Download dataset\n",
    "import os\n",
    "import shutil\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "\n",
    "if not os.path.exists(\"/content/images/valid.zip\"):\n",
    "    # https://drive.google.com/file/d/1ux-mv7250XsgZo-vsk4QIedfGbELl9oZ/view?usp=sharing\n",
    "    # LR - 64x64 images\n",
    "    gdd.download_file_from_google_drive(file_id='1ux-mv7250XsgZo-vsk4QIedfGbELl9oZ',\n",
    "                                        dest_path='./images/valid.zip',\n",
    "                                        unzip=True,\n",
    "                                        showsize=True,\n",
    "                                        )\n",
    "    !rm -rf /content/images/valid.zip\n",
    "\n",
    "# download scripts\n",
    "!wget -q https://raw.githubusercontent.com/veb-101/Esrgan-pytorch/master/trainer.py -O trainer.py\n",
    "!wget -q https://raw.githubusercontent.com/veb-101/Esrgan-pytorch/master/utils.py -O utils.py\n",
    "!wget -q https://raw.githubusercontent.com/veb-101/Esrgan-pytorch/master/models.py -O models.py\n",
    "\n",
    "\n",
    "if not os.path.exists(\"/content/images/train.zip\"):\n",
    "    # https://drive.google.com/file/d/1RGvBO7wVCI4aPNkjy8w-Sl3Kzp2UCqXm/view?usp=sharing\n",
    "    # HR - 256x256 images\n",
    "    gdd.download_file_from_google_drive(file_id='1RGvBO7wVCI4aPNkjy8w-Sl3Kzp2UCqXm',\n",
    "                                        dest_path='./images/train.zip',\n",
    "                                        unzip=True,\n",
    "                                        showsize=True,\n",
    "                                        )\n",
    "    # !rm -rf /content/images/train.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "id": "YRMnpAkFcx1q"
   },
   "outputs": [],
   "source": [
    "import train\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "import importlib\n",
    "\n",
    "\n",
    "seed = 41\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "device = get_default_device()\n",
    "\n",
    "\n",
    "class ESR_Dataset(Dataset):\n",
    "    def __init__(self, num_images=9000, path=r\"images\", train=True):\n",
    "        self.path = path\n",
    "        self.is_train = train\n",
    "\n",
    "        if not os.path.exists(self.path):\n",
    "            raise Exception(f\"[!] dataset is not exited\")\n",
    "\n",
    "        self.image_paths = os.listdir(os.path.join(self.path, \"hr\"))\n",
    "\n",
    "        # self.image_range = image_range if image_range else (0, len(self.image_paths))\n",
    "        # if len(self.image_range) == 1:\n",
    "        #     if self.is_train:\n",
    "        #         self.image_range = (0, self.image_range[0])\n",
    "        #     else:\n",
    "        #         self.image_range = (self.image_range[0], len(self.image_paths))\n",
    "\n",
    "        # self.start = self.image_range[0]\n",
    "        # self.end = self.image_range[1]\n",
    "\n",
    "        self.image_file_name = np.random.choice(\n",
    "            self.image_paths, size=num_images, replace=False)\n",
    "\n",
    "        self.mean = np.array([0.485, 0.456, 0.406])\n",
    "        self.std = np.array([0.229, 0.224, 0.225])\n",
    "        # self.mean = np.array([0.5, 0.5, 0.5])\n",
    "        # self.std = np.array([0.5, 0.5, 0.5])\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        file_name = self.image_file_name[item]\n",
    "        high_resolution = Image.open(os.path.join(self.path, \"hr\", file_name)).convert(\n",
    "            \"RGB\"\n",
    "        )\n",
    "        low_resolution = Image.open(os.path.join(self.path, \"lr\", file_name)).convert(\n",
    "            \"RGB\"\n",
    "        )\n",
    "\n",
    "        if self.is_train:\n",
    "            if random.random() > 0.5:\n",
    "                high_resolution = TF.vflip(high_resolution)\n",
    "                low_resolution = TF.vflip(low_resolution)\n",
    "\n",
    "            if random.random() > 0.5:\n",
    "                high_resolution = TF.hflip(high_resolution)\n",
    "                low_resolution = TF.hflip(low_resolution)\n",
    "\n",
    "            if random.random() > 0.5:\n",
    "                high_resolution = TF.rotate(high_resolution, 90)\n",
    "                low_resolution = TF.rotate(low_resolution, 90)\n",
    "\n",
    "        high_resolution = TF.to_tensor(high_resolution)\n",
    "        low_resolution = TF.to_tensor(low_resolution)\n",
    "\n",
    "        high_resolution = TF.normalize(high_resolution, self.mean, self.std)\n",
    "        low_resolution = TF.normalize(low_resolution, self.mean, self.std)\n",
    "\n",
    "        images = {\"lr\": low_resolution, \"hr\": high_resolution}\n",
    "\n",
    "        return images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bzplM6mdLcY0"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"image_size\": 256,\n",
    "    \"batch_size\": 16,\n",
    "    \"start_epoch\": 0,\n",
    "    \"num_epoch\": 100,\n",
    "    \"sample_batch_size\": 1,\n",
    "    \"checkpoint_dir\": \"./checkpoints\",\n",
    "    \"sample_dir\": \"./samples\",\n",
    "    \"workers\": 6,\n",
    "    \"scale_factor\": 4,\n",
    "    \"num_rrdn_blocks\": 18,\n",
    "    \"nf\": 64,\n",
    "    \"gc\": 32,\n",
    "    \"b1\": 0.9,\n",
    "    \"b2\": 0.999,\n",
    "    \"weight_decay\": 1e-2,\n",
    "    # ------ PSNR ------\n",
    "    \"p_lr\": 2e-4,\n",
    "    \"p_decay_iter\": [20, 40, 60, 80],\n",
    "    \"p_perceptual_loss_factor\": 0,\n",
    "    \"p_adversarial_loss_factor\": 0,\n",
    "    \"p_content_loss_factor\": 1,\n",
    "    # ------------------\n",
    "    # ------ ADVR ------\n",
    "    \"g_lr\": 1e-4,\n",
    "    \"g_decay_iter\": [20, 40, 60, 80],\n",
    "    \"g_perceptual_loss_factor\": 1,\n",
    "    \"g_adversarial_loss_factor\": 5e-3,\n",
    "    \"g_content_loss_factor\": 1e-2,\n",
    "    # ------------------\n",
    "    \"is_psnr_oriented\": True,\n",
    "    \"load_previous_opt\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "L7l_S6LYN_3d"
   },
   "outputs": [],
   "source": [
    "import trainer\n",
    "import models\n",
    "import utils\n",
    "\n",
    "importlib.reload(utils)\n",
    "importlib.reload(models)\n",
    "importlib.reload(trainer)\n",
    "\n",
    "if not os.path.exists(config[\"sample_dir\"]):\n",
    "    os.makedirs(config[\"sample_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LAJ9rhXZgm9J",
    "outputId": "a4d8619d-49d0-46bd-f6b2-6f74644dc129"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size                    : 512\n",
      "batch_size                    : 12\n",
      "start_epoch                   : 2\n",
      "num_epoch                     : 10\n",
      "sample_batch_size             : 1\n",
      "checkpoint_dir                : ./checkpoints\n",
      "sample_dir                    : ./samples\n",
      "workers                       : 6\n",
      "scale_factor                  : 4\n",
      "num_rrdn_blocks               : 11\n",
      "nf                            : 32\n",
      "gc                            : 32\n",
      "b1                            : 0.9\n",
      "b2                            : 0.999\n",
      "weight_decay                  : 0.01\n",
      "p_lr                          : 0.0002\n",
      "p_decay_iter                  : [4, 8, 12, 16]\n",
      "p_perceptual_loss_factor      : 0\n",
      "p_adversarial_loss_factor     : 0\n",
      "p_content_loss_factor         : 1\n",
      "g_lr                          : 0.0001\n",
      "g_decay_iter                  : [10, 20, 35, 50]\n",
      "g_perceptual_loss_factor      : 1\n",
      "g_adversarial_loss_factor     : 0.005\n",
      "g_content_loss_factor         : 0.01\n",
      "is_psnr_oriented              : True\n",
      "load_previous_opt             : True\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ESRGAN start\n",
      "[*] Finding checkpoint 1 in /content/drive/MyDrive/Project-ESRGAN\n",
      "Generator weights loaded.\n",
      "Discriminator weights loaded.\n",
      "Optimizer's state loaded\n",
      "Grad Scaler - Generator loaded\n",
      "Grad Scaler - Discriminator loaded\n",
      "Mini_batch completed: 0\n",
      "Checkpoint: 1 loaded\n",
      "[Epoch 2/11] [Batch 1/750] [content loss 0.0776]\n",
      "[Epoch 2/11] [Batch 376/750] [content loss 0.1027]\n",
      "[Epoch 2/11] [Batch 750/750] [content loss 0.1077]\n",
      "Validation Set: PSNR: 19.367, SSIM:0.581\n",
      "[Epoch 3/11] [Batch 1/750] [content loss 0.0803]\n",
      "[Epoch 3/11] [Batch 376/750] [content loss 0.0771]\n",
      "[Epoch 3/11] [Batch 750/750] [content loss 0.0713]\n",
      "Validation Set: PSNR: 19.419, SSIM:0.588\n",
      "[Epoch 4/11] [Batch 1/750] [content loss 0.0879]\n",
      "[Epoch 4/11] [Batch 376/750] [content loss 0.0738]\n",
      "[Epoch 4/11] [Batch 750/750] [content loss 0.08]\n",
      "Validation Set: PSNR: 19.536, SSIM:0.595\n",
      "[Epoch 5/11] [Batch 1/750] [content loss 0.0745]\n",
      "[Epoch 5/11] [Batch 376/750] [content loss 0.0996]\n",
      "[Epoch 5/11] [Batch 750/750] [content loss 0.0772]\n",
      "Validation Set: PSNR: 19.502, SSIM:0.597\n",
      "[Epoch 6/11] [Batch 1/750] [content loss 0.0752]\n",
      "[Epoch 6/11] [Batch 376/750] [content loss 0.0611]\n",
      "[Epoch 6/11] [Batch 750/750] [content loss 0.0894]\n",
      "Validation Set: PSNR: 19.536, SSIM:0.597\n",
      "[Epoch 7/11] [Batch 1/750] [content loss 0.0861]\n",
      "[Epoch 7/11] [Batch 376/750] [content loss 0.0781]\n",
      "[Epoch 7/11] [Batch 750/750] [content loss 0.0748]\n",
      "Validation Set: PSNR: 19.523, SSIM:0.597\n",
      "[Epoch 8/11] [Batch 1/750] [content loss 0.0931]\n",
      "[Epoch 8/11] [Batch 376/750] [content loss 0.0941]\n",
      "[Epoch 8/11] [Batch 750/750] [content loss 0.0745]\n",
      "Validation Set: PSNR: 19.536, SSIM:0.598\n",
      "[Epoch 9/11] [Batch 1/750] [content loss 0.09]\n",
      "[Epoch 9/11] [Batch 376/750] [content loss 0.0691]\n",
      "[Epoch 9/11] [Batch 750/750] [content loss 0.0995]\n",
      "Validation Set: PSNR: 19.552, SSIM:0.598\n",
      "[Epoch 10/11] [Batch 1/750] [content loss 0.0604]\n",
      "[Epoch 10/11] [Batch 376/750] [content loss 0.0744]\n",
      "[Epoch 10/11] [Batch 750/750] [content loss 0.0722]\n",
      "Validation Set: PSNR: 19.539, SSIM:0.598\n",
      "[Epoch 11/11] [Batch 1/750] [content loss 0.0691]\n",
      "[Epoch 11/11] [Batch 376/750] [content loss 0.0822]\n",
      "[Epoch 11/11] [Batch 750/750] [content loss 0.0724]\n",
      "Validation Set: PSNR: 19.545, SSIM:0.598\n"
     ]
    }
   ],
   "source": [
    "# @title warmup training\n",
    "pin = torch.cuda.is_available()\n",
    "\n",
    "config[\"start_epoch\"] = 0\n",
    "config[\"num_epoch\"] = 100\n",
    "config[\"batch_size\"] = 16\n",
    "config[\"is_psnr_oriented\"] = True\n",
    "config[\"load_previous_opt\"] = True\n",
    "\n",
    "\n",
    "esr_dataset_train = ESR_Dataset(\n",
    "    num_images=9000, path=r\"./images/train\", train=True)\n",
    "\n",
    "esr_dataset_val = ESR_Dataset(\n",
    "    num_images=64, path=r\"./images/valid\", train=False)\n",
    "\n",
    "esr_dataloader_train = DataLoader(\n",
    "    esr_dataset_train,\n",
    "    config[\"batch_size\"],\n",
    "    num_workers=config[\"workers\"],\n",
    "    pin_memory=pin,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "esr_dataloader_val = DataLoader(\n",
    "    esr_dataset_val,\n",
    "    config[\"batch_size\"],\n",
    "    num_workers=config[\"workers\"],\n",
    "    pin_memory=pin,\n",
    ")\n",
    "\n",
    "for key, value in config.items():\n",
    "    print(f\"{key:30}: {value}\")\n",
    "\n",
    "print(\"\\n\\\")\n",
    "print(f\"ESRGAN start\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "psnr_model = train.Trainer(\n",
    "    config, esr_dataloader_train, esr_dataloader_val, device)\n",
    "psnr_model_metrics = psnr_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 906,
     "referenced_widgets": [
      "dc78634245bc4801b5573f5d059f4aae",
      "8b2ac74e2bbf4e5e87c44e45584d11b9",
      "22ad312bd4db41eb9994a16cd2e0d334",
      "d6c40f71acb94442994798f49b12744c",
      "26ba88b5636742679fc4cd8493894bd9",
      "1d44e6ec60414202b020ca355849fccd",
      "d98ef4a517ef4046ac53caed9904e634",
      "5608c9185eb0460e95ecdc59947ffa12"
     ]
    },
    "id": "cVT9mxDbV6sw",
    "outputId": "2acffc5a-a99d-42f0-ea88-4926677745e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size                    : 512\n",
      "batch_size                    : 12\n",
      "start_epoch                   : 12\n",
      "num_epoch                     : 100\n",
      "sample_batch_size             : 1\n",
      "checkpoint_dir                : ./checkpoints\n",
      "sample_dir                    : ./samples\n",
      "workers                       : 6\n",
      "scale_factor                  : 4\n",
      "num_rrdn_blocks               : 11\n",
      "nf                            : 32\n",
      "gc                            : 32\n",
      "b1                            : 0.9\n",
      "b2                            : 0.999\n",
      "weight_decay                  : 0.01\n",
      "p_lr                          : 0.0002\n",
      "p_decay_iter                  : [4, 8, 12, 16]\n",
      "p_perceptual_loss_factor      : 0\n",
      "p_adversarial_loss_factor     : 0\n",
      "p_content_loss_factor         : 1\n",
      "g_lr                          : 0.0001\n",
      "g_decay_iter                  : [10, 20, 35, 50]\n",
      "g_perceptual_loss_factor      : 1\n",
      "g_adversarial_loss_factor     : 0.005\n",
      "g_content_loss_factor         : 0.01\n",
      "is_psnr_oriented              : False\n",
      "load_previous_opt             : False\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ESRGAN start\n",
      "[*] Finding checkpoint 11 in /content/drive/MyDrive/Project-ESRGAN\n",
      "Generator weights loaded.\n",
      "Mini_batch completed: 1500\n",
      "Checkpoint: 11 loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc78634245bc4801b5573f5d059f4aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=574673361.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 12/111] [Batch 1/750][D loss 0.71243] [G loss 0.91814][adversarial loss 0.0035][perceptual loss 0.9138][content loss 0.0008]\n",
      "[Epoch 12/111] [Batch 376/750][D loss 0.00129] [G loss 1.3242][adversarial loss 0.0345][perceptual loss 1.2887][content loss 0.0011]\n",
      "[Epoch 12/111] [Batch 750/750][D loss 1.31021] [G loss 1.47806][adversarial loss 0.0113][perceptual loss 1.4655][content loss 0.0012]\n",
      "Validation Set: PSNR: 17.452, SSIM:0.51\n",
      "[Epoch 13/111] [Batch 1/750][D loss 0.62779] [G loss 1.47641][adversarial loss 0.0087][perceptual loss 1.4667][content loss 0.001]\n",
      "[Epoch 13/111] [Batch 376/750][D loss 0.0022] [G loss 1.20905][adversarial loss 0.0328][perceptual loss 1.1741][content loss 0.0022]\n",
      "[Epoch 13/111] [Batch 750/750][D loss 0.0019] [G loss 1.26491][adversarial loss 0.0337][perceptual loss 1.2295][content loss 0.0017]\n",
      "Validation Set: PSNR: 13.646, SSIM:0.181\n",
      "[Epoch 14/111] [Batch 1/750][D loss 0.00152] [G loss 1.39827][adversarial loss 0.0346][perceptual loss 1.3617][content loss 0.002]\n",
      "[Epoch 14/111] [Batch 376/750][D loss 0.00106] [G loss 1.16794][adversarial loss 0.036][perceptual loss 1.1308][content loss 0.0011]\n",
      "[Epoch 14/111] [Batch 750/750][D loss 0.00103] [G loss 1.44775][adversarial loss 0.0355][perceptual loss 1.411][content loss 0.0013]\n",
      "Validation Set: PSNR: 16.822, SSIM:0.467\n",
      "[Epoch 15/111] [Batch 1/750][D loss 0.00094] [G loss 1.20136][adversarial loss 0.0359][perceptual loss 1.1642][content loss 0.0013]\n"
     ]
    }
   ],
   "source": [
    "pin = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "config[\"start_epoch\"] = 12\n",
    "config[\"num_epoch\"] = 100\n",
    "config[\"batch_size\"] = 12\n",
    "config[\"is_psnr_oriented\"] = False\n",
    "# for loading last ran checkpoint optimizers parameters\n",
    "config[\"load_previous_opt\"] = False\n",
    "\n",
    "\n",
    "esr_dataset_train = ESR_Dataset(num_images=9000,\n",
    "                                path=r\"./images\",\n",
    "                                train=True,\n",
    "                                image_range=(11000,)\n",
    "                                )\n",
    "\n",
    "esr_dataset_val = ESR_Dataset(num_images=config[\"batch_size\"],\n",
    "                              path=r\"./images\",\n",
    "                              train=False,\n",
    "                              image_range=(11000,)\n",
    "                              )\n",
    "\n",
    "esr_dataloader_train = DataLoader(esr_dataset_train,\n",
    "                                  config[\"batch_size\"],\n",
    "                                  num_workers=config[\"workers\"],\n",
    "                                  pin_memory=pin,\n",
    "                                  shuffle=True,)\n",
    "\n",
    "esr_dataloader_val = DataLoader(esr_dataset_val,\n",
    "                                config[\"batch_size\"],\n",
    "                                num_workers=config[\"workers\"],\n",
    "                                pin_memory=pin,)\n",
    "\n",
    "for key, value in config.items():\n",
    "    print(f\"{key:30}: {value}\")\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "print(f\"ESRGAN start\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "trainer = train.Trainer(config, esr_dataloader_train, esr_dataloader_val, device)\n",
    "train_metrics = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "z-etORzSZGeC"
   },
   "outputs": [],
   "source": [
    "#@title Testing Images\n",
    "\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "import numpy as np\n",
    "import models\n",
    "import importlib\n",
    "importlib.reload(models)\n",
    "\n",
    "checkpoint_number = 9\n",
    "\n",
    "checkpoint = torch.load(rf\"/content/checkpoint_{checkpoint_number}.tar\")\n",
    "Model = models.Generator(channels=3, nf=32, gc=32, num_res_blocks=11, scale=4)\n",
    "Model.load_state_dict(checkpoint[rf\"generator_dict_{checkpoint_number}\"])\n",
    "Model.to(device)\n",
    "# print(\"Generator weights loaded.\")\n",
    "\n",
    "\n",
    "image_path = r\"/content/images/lr/00000.png\"\n",
    "\n",
    "\n",
    "def test_image(image_path, model):\n",
    "\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    cv2_imshow(image)\n",
    "    image = image // 255.0\n",
    "    image= image.astype(np.float32)\n",
    "\n",
    "    image = np.moveaxis(image, (0, 1, 2), (1, 2, 0))\n",
    "    image = torch.from_numpy(np.expand_dims(image, 0))\n",
    "    with torch.no_grad():\n",
    "        # with torch.cuda.amp.autocast():\n",
    "        high_res = model(image.to(device))\n",
    "    \n",
    "    high_res = high_res.cpu().detach().permute(0, 2, 3, 1).numpy()\n",
    "    cv2_imshow(high_res[0] * 255.0)\n",
    "    print(high_res.shape)\n",
    "\n",
    "test_image(image_path, Model)\n",
    "\n",
    "\n",
    "# Model.eval()\n",
    "# with torch.no_grad():\n",
    "# with torch.cuda.amp.autocast(enabled=False):\n",
    "    # out = Model(image)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHlfofzaZGhq"
   },
   "outputs": [],
   "source": [
    "# !rm -rf /content/samples\n",
    "# !rm -rf /content/drive/MyDrive/Project-ESRGAN\n",
    "# !rm -rf checkpoint*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gth5dcJUZGxz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ESRGAN_pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1d44e6ec60414202b020ca355849fccd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22ad312bd4db41eb9994a16cd2e0d334": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d44e6ec60414202b020ca355849fccd",
      "max": 574673361,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_26ba88b5636742679fc4cd8493894bd9",
      "value": 574673361
     }
    },
    "26ba88b5636742679fc4cd8493894bd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5608c9185eb0460e95ecdc59947ffa12": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b2ac74e2bbf4e5e87c44e45584d11b9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6c40f71acb94442994798f49b12744c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5608c9185eb0460e95ecdc59947ffa12",
      "placeholder": "​",
      "style": "IPY_MODEL_d98ef4a517ef4046ac53caed9904e634",
      "value": " 548M/548M [00:06&lt;00:00, 85.2MB/s]"
     }
    },
    "d98ef4a517ef4046ac53caed9904e634": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc78634245bc4801b5573f5d059f4aae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_22ad312bd4db41eb9994a16cd2e0d334",
       "IPY_MODEL_d6c40f71acb94442994798f49b12744c"
      ],
      "layout": "IPY_MODEL_8b2ac74e2bbf4e5e87c44e45584d11b9"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
